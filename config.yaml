# Configuration for the SRM RAG system

# --- Mode Selection ---
# Select the active mode: "low", "medium", or "high"
current_mode: "low"

# --- General Settings ---
docs_path: "docs"
index_path: "index"
ollama_model: "llama3.2:3b" # Or "phi3:latest", "llama3.2:3b"
use_direct_results: false  # Set to true to return raw search results without LLM processing
strict_mode: true  # Set to true to enable hallucination detection and validation

# --- RAG Mode Configurations ---
modes:
  # Low mode: Optimized for low-spec CPU systems without GPU
  # Minimal resource usage while maintaining basic RAG functionality
  low:
    embedding_model: "all-MiniLM-L6-v2"  # Best balance of speed/quality for CPU
                                      # For very low-spec systems, consider: "all-distilroberta-v1"
    reranker_model: "cross-encoder/ms-marco-MiniLM-L-2-v2"  # Lightweight reranker

    # Retrieval settings - optimized for low-spec systems
    top_k_bm25: 6        # Reduced from 8 for faster BM25 processing
    top_k_faiss: 6       # Reduced from 8 for faster vector search
    top_k_reranked: 4    # Reduced from 6 to minimize reranking overhead

    # Advanced features - minimal for performance
    enable_multi_query_generation: false  # Disabled - saves CPU cycles
    enable_reranking: false               # Disabled - heavy CPU operation
    enable_multi_stage_generation: false  # Disabled - not needed for low mode
    enable_diversity_selection: true      # Keep for basic quality
    enable_document_diversity: true       # Keep for multi-document results

    # Performance optimizations for low-spec systems
    batch_size: 16                        # Smaller batches for low memory
    max_concurrent_searches: 1            # Sequential processing
    embedding_cache_size: 100             # Limit memory usage

    # Context management - reduced for performance
    max_context_length: 4000              # Reduced context window

  # Medium mode: Balanced speed and quality.
  # Enables reranking and other key features for better accuracy.
  medium:
    embedding_model: "all-MiniLM-L6-v2"
    reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    
    # Retrieval settings
    top_k_bm25: 10
    top_k_faiss: 10
    top_k_reranked: 7
    
    # Advanced features
    enable_multi_query_generation: true
    enable_reranking: true
    enable_multi_stage_generation: true
    
    # Context management
    max_context_length_simple: 8000
    max_context_length_medium: 10000
    max_context_length_complex: 14000

  # High mode: Best quality, slowest response.
  # Uses more candidates for retrieval and reranking for maximum thoroughness.
  high:
    embedding_model: "all-MiniLM-L6-v2" # Consider a more powerful model for high mode
    reranker_model: "cross-encoder/ms-marco-MiniLM-L-6-v2"
    
    # Retrieval settings
    top_k_bm25: 12
    top_k_faiss: 12
    top_k_reranked: 7
    
    # Advanced features (all enabled)
    enable_multi_query_generation: true
    enable_reranking: true
    enable_multi_stage_generation: true
    
    # Context management
    max_context_length_simple: 8000
    max_context_length_medium: 10000
    max_context_length_complex: 16000
